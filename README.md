# ðŸ§  Machine Learning to Analyze Brain of Zebrafish

**ðŸ‘¤ Author**: Ans Imran  
**ðŸ›ï¸ Lab**: Laboratoire Jean Perrin (LJP), Sorbonne UniversitÃ©  
**â³ Duration**: 5 months & 5 days  
**ðŸ”¬ Focus**: Machine Learning for Neural Data Analysis  

---

## ðŸ“Œ Summary of Work

- ðŸ› ï¸ Tuned the regularization parameter (Î») for compositional Restricted Boltzmann Machines (cRBMs) to improve training stability and reduce overfitting.
- ðŸ§  Used cRBMs to model functional connectivity in zebrafish brain data recorded from ~40,000 neurons.
- ðŸ“ Evaluated models based on how well they reproduced brain activity statistics using nRMSE metrics.
- ðŸ“Š Analyzed connectivity patterns using PCA and K-means clustering.
- âœ… Built a pipeline to identify reliable (â€œgoodâ€) models based on performance thresholds.

---

## ðŸ” Project Overview

### 1ï¸âƒ£ Regularization Tuning

**ðŸŽ¯ Goal**: Find the right Î» value for L2L1 regularization in cRBMs to avoid overfitting while keeping the model useful.

**ðŸ”§ What I Did**:
- Trained 600+ models across two Î» ranges: `[0.005â€“0.1]` and `[0.5â€“5.0]`.
- Measured each modelâ€™s ability to reproduce 5 brain activity statistics.
- Defined â€œbadâ€ models as those with nRMSE > 1.0 or NaN.
- Found Î» = **0.09** to work best:
  - <10% bad models  
  - nRMSE norm â‰¤ 0.55

**ðŸ’¡ Concepts Used**:
- Hyperparameter tuning  
- L2L1 regularization  
- Model evaluation (custom metrics)  
- Train/test splitting

---

### 2ï¸âƒ£ Functional Connectivity Analysis

**ðŸŽ¯ Goal**: Test if connectivity patterns stay consistent across models with different Î» values.

**ðŸ”§ What I Did**:
- Generated coupling (connectivity) matrices from model weights.
- Flattened and projected them using PCA.
- Grouped them using K-means clustering.
- Found two clear clusters based on Î» range, but structure of voxel connections was preserved.

**ðŸ’¡ Concepts Used**:
- PCA (dimensionality reduction)  
- K-means clustering  
- nRMSE for matrix similarity

---

### 3ï¸âƒ£ Model Evaluation

**ðŸŽ¯ Goal**: Define a way to identify models that generalize well to unseen data.

**ðŸ”§ What I Did**:
- Used 4 of the 5 brain statistics to compute a 4D error vector per model.
- Calculated the L2 norm of this vector.
- Models with norms â‰¤ 0.55 were considered â€œgoodâ€.
- Confirmed results using visual tools like identity and polar plots.

**ðŸ’¡ Concepts Used**:
- Custom model scoring  
- Error thresholding  
- Diagnostic plotting

---

### 4ï¸âƒ£ Tools and Workflow

| ðŸ§© Area             | âš™ï¸ Tools/Concepts Used                           |
|--------------------|--------------------------------------------------|
| Data Preparation   | Voxelization, z-score normalization              |
| Modeling           | cRBMs with L2L1 regularization                   |
| Evaluation & Viz   | nRMSE, heatmaps, polar plots, PCA, K-means      |
| Programming        | Python, NumPy, SciPy, scikit-learn, matplotlib   |
| Environment        | Jupyter Notebooks                                |

---

## âœ… Conclusion

- Regularization strength directly impacted both model quality and sparsity.
- Î» in the range [0.05â€“0.1] produced the best results.
- Even lower-performing models showed similar connectivity structures.
- Functional relationships between brain voxels can be consistently captured by cRBMs.

---

## ðŸ”„ Future Work

- Extend training to multiple zebrafish to test pattern consistency across individuals.
- Compare inferred functional connectivity to known structural connectivity if available.

---

## ðŸ“Ž Appendix

- ðŸ“„ Full Report: [Ans IMRAN - internship report updated.pdf](./Ans%20IMRAN%20-%20internship%20report%20updated.pdf)  
- ðŸ§¾ Code: *[Link to repository if available]*  
- ðŸ“Š Visuals: Included in the report (e.g., coupling matrices, PCA plots, nRMSE trends)
