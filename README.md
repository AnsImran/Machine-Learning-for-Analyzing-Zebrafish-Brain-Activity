# **Internship details start after the images.**

<img src="/figures/1.jpg" alt="1" width="1000"/>
<img src="/figures/2.jpg" alt="2" width="1000"/>
<img src="/figures/3.jpg" alt="3" width="1000"/>
<img src="/figures/l2l1__vs__norms_of_nrmse_vecs__and__percentage_of_explosions.jpg" alt="4" width="1000"/>



# ğŸ§  Machine Learning to Analyze Brain of Zebrafish

**ğŸ‘¤ Author**: Ans Imran  
**ğŸ›ï¸ Lab**: Laboratoire Jean Perrin (LJP), Sorbonne UniversitÃ©  
**â³ Duration**: 5 months & 5 days  
**ğŸ”¬ Focus**: Machine Learning for Neural Data Analysis  

---

## ğŸ“Œ Summary of Work

- ğŸ› ï¸ Tuned the regularization parameter (Î») for compositional Restricted Boltzmann Machines (cRBMs) to improve training stability and reduce overfitting.
- ğŸ§  Used cRBMs to model functional connectivity in zebrafish brain data recorded from ~40,000 neurons.
- ğŸ“ Evaluated models based on how well they reproduced brain activity statistics using nRMSE metrics.
- ğŸ“Š Analyzed connectivity patterns using PCA and K-means clustering.
- âœ… Built a pipeline to identify reliable (â€œgoodâ€) models based on performance thresholds.

---

## ğŸ” Project Overview

### 1ï¸âƒ£ Regularization Tuning

**ğŸ¯ Goal**: Find the right Î» value for L2L1 regularization in cRBMs to avoid overfitting while keeping the model useful.

**ğŸ”§ What I Did**:
- Trained 600+ models across two Î» ranges: `[0.005â€“0.1]` and `[0.5â€“5.0]`.
- Measured each modelâ€™s ability to reproduce 5 brain activity statistics.
- Defined â€œbadâ€ models as those with nRMSE > 1.0 or NaN.
- Found Î» = **0.09** to work best:
  - <10% bad models  
  - nRMSE norm â‰¤ 0.55

**ğŸ’¡ Concepts Used**:
- Hyperparameter tuning  
- L2L1 regularization  
- Model evaluation (custom metrics)  
- Train/test splitting

---

### 2ï¸âƒ£ Functional Connectivity Analysis

**ğŸ¯ Goal**: Test if connectivity patterns stay consistent across models with different Î» values.

**ğŸ”§ What I Did**:
- Generated coupling (connectivity) matrices from model weights.
- Flattened and projected them using PCA.
- Grouped them using K-means clustering.
- Found two clear clusters based on Î» range, but structure of voxel connections was preserved.

**ğŸ’¡ Concepts Used**:
- PCA (dimensionality reduction)  
- K-means clustering  
- nRMSE for matrix similarity

---

### 3ï¸âƒ£ Model Evaluation

**ğŸ¯ Goal**: Define a way to identify models that generalize well to unseen data.

**ğŸ”§ What I Did**:
- Used 4 of the 5 brain statistics to compute a 4D error vector per model.
- Calculated the L2 norm of this vector.
- Models with norms â‰¤ 0.55 were considered â€œgoodâ€.
- Confirmed results using visual tools like identity and polar plots.

**ğŸ’¡ Concepts Used**:
- Custom model scoring  
- Error thresholding  
- Diagnostic plotting

---

### 4ï¸âƒ£ Tools and Workflow

| ğŸ§© Area             | âš™ï¸ Tools/Concepts Used                           |
|--------------------|--------------------------------------------------|
| Data Preparation   | Voxelization, z-score normalization              |
| Modeling           | cRBMs with L2L1 regularization                   |
| Evaluation & Viz   | nRMSE, heatmaps, polar plots, PCA, K-means      |
| Programming        | Python, Julia, NumPy, SciPy, scikit-learn, matplotlib   |
| Environment        | Jupyter Notebooks                                |

---

## âœ… Conclusion

- Regularization strength directly impacted both model quality and sparsity.
- Î» in the range [0.05â€“0.1] produced the best results.
- Even lower-performing models showed similar connectivity structures.
- Functional relationships between brain voxels can be consistently captured by cRBMs.

---

## ğŸ”„ Future Work

- Extend training to multiple zebrafish to test pattern consistency across individuals.

---

## ğŸ“ Appendix

- ğŸ“„ Full Report: [Internship Report](Full Internship Report.pdf)
- ğŸ§¾ Code: *the code is private (property of Laboratoire Jean Perrin)*  
- ğŸ“Š Visuals: Included in the report (e.g., coupling matrices, PCA plots, nRMSE trends)
